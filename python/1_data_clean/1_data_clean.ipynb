{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7739e5ea",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "In this file, we will clean the two datasets used in the paper Humans display interindividual differences in the latent mechanisms underlying fear generalization behaviour. We will also generate the required data structures for modeling and create some visualizations to better understand the fundamental structure of the data.\n",
    "\n",
    "If you download everything on the OSF, you can open the markdown files with the R project - Multiplaths_Generalization.Rproj. By doing so, you won’t need to change the depository of, for example, model scripts and data files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a22688f",
   "metadata": {},
   "source": [
    "## 1. Dataset 1: Simple conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0407bfb9",
   "metadata": {},
   "source": [
    "### 1.1 Pre-process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb149b3",
   "metadata": {},
   "source": [
    "This code chunk performs the following tasks:\n",
    "\n",
    "It creates a list of data files for the first experiment, excluding the data for participants 15, 17, and 31.\n",
    "\n",
    "It loads the data and processes it by:\n",
    "\n",
    "Creating a stimulus column and replacing 999 values with NA\n",
    "Creating a stimulus_phy column\n",
    "Removing practice trials and ITI trials\n",
    "Creating a CStrials and CS_phy column\n",
    "Renaming the Size column to Per_size and selecting the desired columns\n",
    "It creates a Phy_size column.\n",
    "It changes the levels of the stimulus and stimulus_phy columns.\n",
    "\n",
    "It creates a trials column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4012b6c5-72fb-4975-b069-e029a03172a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import os\n",
    "from natsort import natsorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b1035-6ece-43c7-9c0a-910acfee20a8",
   "metadata": {},
   "source": [
    "Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0c7dc-b0bb-4a16-bdca-bd29b6429cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nactrials_1 = 14\n",
    "Nactrials_2 = 24\n",
    "Ngetrials_1 = 174\n",
    "Ngetrials_2 = 156\n",
    "Ntrials_1 = Nactrials_1 + Ngetrials_1\n",
    "Ntrials_2 = Nactrials_2 + Ngetrials_2\n",
    "\n",
    "\n",
    "start= 50.8\n",
    "end = 119.42\n",
    "step = 7.624\n",
    "\n",
    "# Create a sequence of stimulus sizes ranging from 50.80 to 119.42 with a step size of 7.624.\n",
    "stimulus_size =  np.round(np.arange(start, end + step, step), 2)\n",
    "\n",
    "# Create a list of stimulus levels for stimulus_level_1 including CS+\n",
    "stimulus_level_1 = [\"S4\", \"S5\", \"S6\", \"CS+\", \"S8\", \"S9\", \"S10\"]\n",
    "\n",
    "# Create a vector of stimulus levels for stimulus_level_2. including cs+ and cs-\n",
    "stimulus_level_2 = [\"CS+\",\"S2\",\"S3\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\",\"CS-\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0115c-4634-4ae2-b2e3-fecb6d82288b",
   "metadata": {},
   "source": [
    "Load data of experiment 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3edf57-ee8a-4549-ab03-dbf4e9033daa",
   "metadata": {},
   "source": [
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303e145-8f0e-42cc-b47a-3b00483428ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of data files for the first experiment.\n",
    "# The data for participants 15, 17, and 31 are broken, so they are excluded from the list.\n",
    "participants = list(range(1, 15)) + list(range(16, 31)) + list(range(32, 37)) + list(range(38, 44))\n",
    "data_s1_list = [f\"../../Data/Experiment_1/{p}/{p}_results.txt\" for p in participants]\n",
    "data_s1 = (\n",
    "    pd.concat(\n",
    "        [pd.read_csv(file, sep=\"\\t\").assign(participant=participant) \n",
    "         for participant, file in enumerate(data_s1_list, start=1)],\n",
    "        ignore_index=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a stimulus column and replace 999 values with NaN\n",
    "data_s1['stimulus'] = data_s1.apply(lambda row: 'S4' if row['C4'] == 1\n",
    "                                                else 'S5' if row['C5'] == 1\n",
    "                                                else 'S6' if row['C6'] == 1\n",
    "                                                else 'CS+' if row['C7'] == 1\n",
    "                                                else 'S8' if row['C8'] == 1\n",
    "                                                else 'S9' if row['C9'] == 1\n",
    "                                                else 'S10' if row['C10'] == 1\n",
    "                                                else 'ITI', axis=1)\n",
    "data_s1['Size'] = data_s1['Size'].replace(999, pd.NA)\n",
    "data_s1['US_expect'] = data_s1['US_expect'].replace(999, pd.NA)\n",
    "\n",
    "# Create a stimulus_phy column.\n",
    "data_s1['stimulus_phy'] = data_s1['stimulus'].replace({\"CS+\": \"S7\"})\n",
    "# Remove practice trials and ITI trials.\n",
    "data_s1 = data_s1[(data_s1['block number'] != 2) & (data_s1['stimulus'] != \"ITI\")]\n",
    "\n",
    "\n",
    "\n",
    "# Create CS identifier column and Physical size column  .\n",
    "data_s1['CStrials'] = np.where(data_s1['stimulus'] == 'CS+', 1, 0).astype(int)\n",
    "data_s1['CS_phy'] =  stimulus_size[6] \n",
    "\n",
    "# Rename the Size column to Per_size and select the desired columns.\n",
    "data_s1.rename(columns={'Size': 'Per_size'}, inplace=True)\n",
    "\n",
    "selected_cols = ['participant', 'block number', 'trial number', 'US','Startle_Circle','Startle_ITI', 'Per_size', 'US_expect', 'Total_trial_nr', 'stimulus', 'stimulus_phy', 'CStrials','CS_phy']\n",
    "data_s1 = data_s1[selected_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stimulus_levels = [\"S4\", \"S5\", \"S6\", \"CS+\", \"S8\", \"S9\", \"S10\"]\n",
    "stimulus_size_mapping = dict(zip(stimulus_levels, stimulus_size[3:10]))\n",
    "data_s1['Phy_size'] = data_s1['stimulus'].map(stimulus_size_mapping).astype(float)\n",
    "\n",
    "\n",
    "data_s1['stimulus'] = pd.Categorical(data_s1['stimulus'], categories=stimulus_level_1, ordered=True)\n",
    "stimulus_phy_levels = [f'S{i}' for i in range(4, 11)]\n",
    "data_s1['stimulus_phy'] = pd.Categorical(data_s1['stimulus_phy'], categories=stimulus_phy_levels, ordered=True)\n",
    "\n",
    "\n",
    "# Create a trial column.\n",
    "data_s1['trials'] = data_s1.groupby('participant').cumcount() + 1\n",
    "# data_s1.to_csv(\"../../vars/r/draft/data_s1_first_py.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae7179-9d27-4c66-8855-ea159ea09e98",
   "metadata": {},
   "source": [
    "### 1.2 Long-wide format (for JAGS in R - PYMC in Python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1dd039-d164-4d8a-89c4-f78460080416",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list_s1 = {\n",
    "    'y': 'US_expect',\n",
    "    'Sphy': 'Phy_size',\n",
    "    'Sper': 'Per_size',\n",
    "    'CSphy': 'CS_phy',\n",
    "    'CSindicator1': 'CStrials',\n",
    "    'CSindicator2': 'CStrials',\n",
    "    'shock': 'US'\n",
    "}\n",
    "jags_input_s1_pre = {}\n",
    "# Convert the data from long to wide format.\n",
    "for key, value in variable_list_s1.items():\n",
    "    df_wide = data_s1.pivot(index='participant', columns='trials', values=value).reset_index()\n",
    "     # Reorder the rows by participant.\n",
    "    df_wide = df_wide.set_index('participant').loc[natsorted(df_wide['participant'])].reset_index()\n",
    "    df_wide = df_wide.drop(columns=['participant'])\n",
    "    jags_input_s1_pre[key] = df_wide\n",
    "\n",
    "\n",
    "# Set all values in the CSindicator2 column from trial 15 to 188 to 0.\n",
    "jags_input_s1_pre['CSindicator2'].iloc[:, 14:188] = 0  \n",
    "\n",
    "# for key, df in jags_input_s1_pre.items():\n",
    "#     # Save each DataFrame individually to a CSV file with the variable name as part of the file name\n",
    "#     df.to_csv(f\"../../vars/r/draft/jags_py/jags_input_s1_pre_{key}_py.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa7f05-7a37-45bf-8c06-c56f4cc0308b",
   "metadata": {},
   "source": [
    "### 1.3 Compute distance to CS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7379f98",
   "metadata": {},
   "source": [
    "This code chunk has the following purposes:\n",
    "\n",
    "Create a CS index by summing the values of the CSindicator1 column and calculating the sum of the CSindicator1 values up to the current column. Extracts CS perception by selecting the Per_size column for rows where stimulus is “CS+”, adding a trials column, and converting the data to wide format. The CS_per_s1 data is reordered by participant and the first column is removed.\n",
    "\n",
    "Extracts CS perception by selecting the Per_size column for rows where stimulus is “CS+”, adding a trials column, and converting the data to wide format. The CS_per_s1 data is reordered by participant and the first column is removed.\n",
    "\n",
    "Computes the moving average for CS perception by looping through the rows and columns of the CS_per_s1 data and calculating the sum of the CS_per_s1 values up to the current column, excluding NA values.\n",
    "\n",
    "Creates empty matrices to store perceptual and physical distance data.\n",
    "\n",
    "Computes the perceptual and physical distances by looping through the rows and columns of the data and calculating the absolute value of the difference between the perceptual size/physical size and the CS perception/stimulus size, respectively.\n",
    "\n",
    "Merges the distance data with the data_s1 data by participant and trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CS index.\n",
    "CS_index = np.zeros_like(jags_input_s1_pre['CSindicator1'])\n",
    "\n",
    "\n",
    "# cs_index 3btswi mtl 3dad l kl participant 3l 3wemid tb3o, iza kan CSindicator1 == 1 3btzid, iza la bb2a nfs l r2m\n",
    "# Loop through each row and column of the CSindicator1 column.\n",
    "for i in range(CS_index.shape[0]):\n",
    "    for j in range(CS_index.shape[1]):\n",
    "        # Calculate the sum of the CSindicator1 values up to the current column.\n",
    "        CS_index[i, j] = jags_input_s1_pre['CSindicator1'].iloc[i, :j+1].sum()\n",
    "# jags_input_s1_pre['CS_index'] = pd.DataFrame(CS_index, index=jags_input_s1_pre['CSindicator1'].index, columns=jags_input_s1_pre['CSindicator1'].columns)\n",
    "CS_index_df = pd.DataFrame(CS_index, index=jags_input_s1_pre['CSindicator1'].index, columns=jags_input_s1_pre['CSindicator1'].columns)\n",
    "jags_input_s1_pre['CS_index']  = CS_index_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c322f-c034-4f8e-b07e-b6253f20d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract CS perception.\n",
    "#CS_PER_S1: filter rows of data_s1 where stimulus = cs+ and take only two columns: participant and per_size , shape is random num of rows and two columns\n",
    "CS_per_s1 = data_s1[data_s1['stimulus'] == 'CS+'][['participant', 'Per_size']].copy()\n",
    "# adding trials column which is a cummulative based on the participant\n",
    "CS_per_s1['trials'] = CS_per_s1.groupby('participant').cumcount() + 1\n",
    "# convert data from long to wide format\n",
    "CS_per_s1 = CS_per_s1.sort_values(by=['participant', 'trials'])\n",
    "CS_per_s1_wide = CS_per_s1.pivot(index='participant', columns='trials', values='Per_size').reset_index()\n",
    "# Now cs_per_s1_wide having each participant in a row and the columns are the values of per_size for this participant but per_size might be NA\n",
    "# CS_per_s1.drop(columns=CS_per_s1.columns[0], inplace=True)\n",
    "\n",
    "# Convert all columns to numeric, errors='coerce' will convert non-convertible values to NaN\n",
    "CS_per_s1 = CS_per_s1.apply(pd.to_numeric, errors='coerce')\n",
    "CS_per_s1[(CS_per_s1['participant'] == 2) &  (CS_per_s1['trials'] == 4)]\n",
    "CS_per_s1_wide.set_index('participant', inplace=True)\n",
    "\n",
    "# Compute moving average for CS perception.\n",
    "CS_per_updatemean_s1 = pd.DataFrame(index=CS_per_s1_wide.index, columns=CS_per_s1_wide.columns)\n",
    "\n",
    "for i in range(len(CS_per_s1_wide)):\n",
    "    for j in range(1,len(CS_per_s1_wide.columns) + 1):\n",
    "        # Calculate the sum of the CS_per_s1 values up to the current column, excluding NA values.\n",
    "        CS_per_updatemean_s1.iloc[i,j - 1] = CS_per_s1_wide.iloc[i, :j].dropna().sum() / (j)\n",
    "\n",
    "# CS per updatemean_s1 is checked compared to R result\n",
    "# CS_per_updatemean_s1.to_csv(\"../../vars/r/draft/cs_per_py.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7994848",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create empty matrices for perceptual and physical distance data\n",
    "d_per = np.zeros((40, 188))\n",
    "d_phy = np.zeros((40, 188))\n",
    "d_list_s1 = {'d_per': d_per, 'd_phy': d_phy}\n",
    "\n",
    "for i in range(1,41):\n",
    "    for j in range(1,189):\n",
    "        cs_idx =  jags_input_s1_pre['CS_index'].iloc[i -1, j-1 ]\n",
    "        s_per = jags_input_s1_pre['Sper'].iloc[i - 1,j - 1]\n",
    "        if pd.isna(s_per):\n",
    "            d_per[i-1,j-1] = np.nan\n",
    "        else: \n",
    "            d_per[i- 1,j- 1] = round(abs( s_per -  CS_per_updatemean_s1.iloc[i-1, cs_idx - 1]), 2)\n",
    "\n",
    "        s_phy = jags_input_s1_pre['Sphy'].iloc[i - 1,j - 1]\n",
    "        d_phy[i-1,j-1] = np.round(abs(s_phy - stimulus_size[6]),2)\n",
    "\n",
    "d_list_s1['d_per'] = d_per\n",
    "d_list_s1['d_phy'] = d_phy\n",
    "\n",
    "\n",
    "#d_phy, d_per is correct and compared with R\n",
    "# pd.DataFrame(d_per).to_csv(\"../../vars/r/draft/d_per.csv\")\n",
    "# pd.DataFrame(d_phy).to_csv(\"../../vars/r/draft/d_phy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dr = pd.melt(d_list_s1['d_per'], var_name=[\"participant\", \"trials\"], value_name=\"dper\").rename(columns={\"participant\": \"Var1\", \"trials\": \"Var2\"})\n",
    "reshaped = {}\n",
    "for key in ['d_per', 'd_phy']:\n",
    "    ar = d_list_s1[key].flatten()\n",
    "    reshaped[key] = pd.DataFrame({\n",
    "        \"participant\": np.repeat(range(1, d_per.shape[0] + 1), d_per.shape[1]),\n",
    "        \"trials\": np.tile(range(1, d_per.shape[1] + 1), d_per.shape[0]),\n",
    "        key: ar,\n",
    "    })\n",
    "    # reshaped[key]['participant'] = reshaped[key]['participant'].astype(str)\n",
    "\n",
    "    reshaped[key] = reshaped[key].sort_values(by=[\"trials\", \"participant\"]).reset_index(drop=True)\n",
    "    data_s1 = data_s1.merge(reshaped[key], on=['participant', 'trials'])\n",
    "\n",
    "# data_s1.columns\n",
    "data_s1 = data_s1[['participant', 'trials', \"d_phy\" , \"d_per\", \"block number\", \"trial number\", \"US\", \"Startle_Circle\", \"Startle_ITI\", \"Per_size\", \"US_expect\", \"Total_trial_nr\", \"stimulus\", \"stimulus_phy\", \"CStrials\", \"CS_phy\", \"Phy_size\"]]\n",
    "# data_s1.to_csv(\"../../vars/r/draft/ds1_py.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f799d6-2de9-4a72-9746-74ee23ea50bf",
   "metadata": {},
   "source": [
    "### 1.4 JAGS (PYMC) input file :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5233e4f-9aa5-478a-9965-183242bb1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_input_s1(L, indicator=None):\n",
    "    # Assuming jags_input_s1_pre and d_list_s1 are already defined as pandas DataFrames or appropriate data structures\n",
    "    data = {\n",
    "        'Nparticipants': jags_input_s1_pre['y'].shape[0],\n",
    "        'Ntrials': jags_input_s1_pre['y'].shape[1],\n",
    "        'Nactrials': 14,\n",
    "        'd_per': [d_list_s1['d_per'][:, 14:188], d_list_s1['d_per']][L-1],\n",
    "        'd_phy': [d_list_s1['d_phy'][:, 14:188], d_list_s1['d_phy']][L-1],\n",
    "        'y': np.array([jags_input_s1_pre['y'].iloc[:, 14:188], jags_input_s1_pre['y']][L-1])\n",
    "    }\n",
    "    \n",
    "    if L == 2:\n",
    "        additional_data = {\n",
    "            'r': np.array(jags_input_s1_pre['shock']),\n",
    "            'k': np.array([jags_input_s1_pre['CSindicator1'], jags_input_s1_pre['CSindicator2']][indicator-1])\n",
    "        }\n",
    "        data.update(additional_data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "#input data without learning trials\n",
    "Data1_JAGSinput_G = data_input_s1(1)\n",
    "#input data with an assumption of non-continuous learning \n",
    "Data1_JAGSinput_LG = data_input_s1(2, 2)\n",
    "#input data with an assumption of continuous learning \n",
    "Data1_JAGSinput_CLG = data_input_s1(2, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_data_as_pickle(data, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "\n",
    "# Data1_JAGSinput_G has been compared with R and it is correct\n",
    "# Data1_JAGSinput_LG has been compared with R and it is correct\n",
    "# Data1_JAGSinput_CLG has been compared with R and it is correct\n",
    "# data_s1 has been compared with R and it is correct\n",
    "\n",
    "# Save as pickles\n",
    "save_data_as_pickle(Data1_JAGSinput_G, '../../Data/res_py/Data1_JAGSinput_G.pkl')\n",
    "save_data_as_pickle(Data1_JAGSinput_LG, '../../Data/res_py/Data1_JAGSinput_LG.pkl')\n",
    "save_data_as_pickle(Data1_JAGSinput_CLG, '../../Data/res_py/Data1_JAGSinput_CLG.pkl')\n",
    "save_data_as_pickle(data_s1, '../../Data/res_py/Data_s1.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2eecfc-a9d1-459c-bd37-172e9b713fc2",
   "metadata": {},
   "source": [
    "## 2. Dataset 2: Differential conditioning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afaf81a-91cf-419c-aff4-6ae72ad9c809",
   "metadata": {},
   "source": [
    "### 2.1 Pre-process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bee3ac-cfe0-4435-9eb5-1d06496852cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data list for data loading\n",
    "participants_2 = list(range(41, 81))\n",
    "data_s2_list = [f\"../../Data/Experiment_2/{p}/{p}_results.txt\" for p in participants_2]\n",
    "data_s2 = pd.concat([pd.read_csv(file, sep=\"\\t\") for file in data_s2_list], keys=range(1, 41), names=['participant']).reset_index()\n",
    "\n",
    "\n",
    "# Load data to 'data_s2' and process data\n",
    "\n",
    "conditions = [\n",
    "    ((data_s2['C1'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C10'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C2'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C9'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C3'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C8'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C4'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C7'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C5'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C6'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C6'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C5'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C7'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C4'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C8'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C3'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C9'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C2'] == 1) & (data_s2['group'] == 2)),\n",
    "    ((data_s2['C10'] == 1) & (data_s2['group'] == 1)) | ((data_s2['C1'] == 1) & (data_s2['group'] == 2))\n",
    "]\n",
    "choices = [\"CS+\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"CS-\"]\n",
    "  # Create stimulus column ; Change 999 to NA\n",
    "data_s2['stimulus'] = np.select(conditions, choices, default='ITI')\n",
    "data_s2['Size'] = data_s2['Size'].replace(999, np.nan)\n",
    "\n",
    "data_s2['US_expect'] = data_s2['US_expect'].replace(999, np.nan)\n",
    "\n",
    "conditions = [\n",
    "    (data_s2['C1'] == 1),\n",
    "    (data_s2['C2'] == 1),\n",
    "    (data_s2['C3'] == 1),\n",
    "    (data_s2['C4'] == 1),\n",
    "    (data_s2['C5'] == 1),\n",
    "    (data_s2['C6'] == 1),\n",
    "    (data_s2['C7'] == 1),\n",
    "    (data_s2['C8'] == 1),\n",
    "    (data_s2['C9'] == 1),\n",
    "]\n",
    "choices = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\"]\n",
    "data_s2['stimulus_phy'] = np.select(conditions, choices, default='S10')\n",
    "\n",
    "data_s2['CSptrials'] = np.where(data_s2['stimulus'] == \"CS+\", 1,0)\n",
    "data_s2['CSmtrials'] = np.where(data_s2['stimulus'] == 'CS-', 1, 0)\n",
    "# Remove practice trials and ITI trials\n",
    "data_s2 = data_s2[(data_s2['block number'] != 2) & (data_s2['stimulus'] != 'ITI')]\n",
    "data_s2['USp'] = np.where((data_s2['CSptrials'] == 1) & (data_s2['US'] == 1), 1, 0)\n",
    "data_s2['USm'] = np.where((data_s2['CSmtrials'] == 1) & (data_s2['US'] == 0), -1, 0)\n",
    "data_s2['CS_phy_p'] = np.where(data_s2['group'] == 1, stimulus_size[0], stimulus_size[9])\n",
    "data_s2['CS_phy_m'] = np.where(data_s2['group'] == 1, stimulus_size[9], stimulus_size[0])\n",
    "data_s2 = data_s2.rename(columns={'Size': 'Per_size'})\n",
    "\n",
    "# Create a new column called 'Phy_size' that maps the stimulus_phy column to a numeric value based on the values in 'stimulus_size'\n",
    "stimulus_phy_map = {f'S{i}': stimulus_size[i-1] for i in range(1, 11)}\n",
    "data_s2['Phy_size'] = data_s2['stimulus_phy'].map(stimulus_phy_map)\n",
    "# Convert the 'stimulus' and 'stimulus_phy' columns to factors\n",
    "data_s2['stimulus'] = pd.Categorical(data_s2['stimulus'], categories=stimulus_level_2)\n",
    "data_s2['stimulus_phy'] = pd.Categorical(data_s2['stimulus_phy'], categories=[f'S{i}' for i in range(1, 11)])\n",
    "# Create a new column called 'trials' that is a sequence of numbers for each participant\n",
    "data_s2['trials'] = data_s2.groupby('participant').cumcount() + 1\n",
    "\n",
    "selected_cols=  [\"participant\", \"block number\", \"trial number\", \"US\", \"Startle_Circle\", \"Startle_ITI\",\"Per_size\", \"US_expect\", \"Total_trial_nr\", \"group\", \"stimulus\", \"stimulus_phy\", \"CSptrials\", \"CSmtrials\", \"USp\", \"USm\",\"CS_phy_p\", \"CS_phy_m\", 'Phy_size', 'trials']\n",
    "\n",
    "data_s2 = data_s2[selected_cols]\n",
    "# data_s2.to_csv(\"../../vars/r/draft/ds2py.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ed1ac-92e2-4a9a-8b64-efc2f87fbccf",
   "metadata": {},
   "source": [
    "### 2.2 Long-wide format (for JAGS - PYMC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b2469-067e-474c-853c-95a6e26f7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a list of variables to extract from the long format data\n",
    "variable_list_s2 = {\n",
    "    'y': 'US_expect', \n",
    "    'Sphy': 'Phy_size', \n",
    "    'Sper': 'Per_size', \n",
    "    'CSphy_p': 'CS_phy_p', \n",
    "    'CSphy_m': 'CS_phy_m',\n",
    "    'CSindicator1_p': 'CSptrials', \n",
    "    'CSindicator2_p': 'CSptrials', \n",
    "    'CSindicator1_m': 'CSmtrials', \n",
    "    'CSindicator2_m': 'CSmtrials', \n",
    "    'US_p': 'USp', \n",
    "    'US_m': 'USm'\n",
    "}\n",
    "\n",
    "\n",
    "# Convert the data from long to wide format\n",
    "jags_input_s2_pre = {}\n",
    "for key, value in variable_list_s2.items():\n",
    "    wide_df = data_s2.pivot(index='participant', columns='trials', values=value)\n",
    "    # Reorder the rows by participant\n",
    "    wide_df.sort_index(inplace=True)\n",
    "    jags_input_s2_pre[key] = wide_df\n",
    "\n",
    "# Set all values in the CSindicator2_p column from trial 25 to 180 to 0\n",
    "jags_input_s2_pre['CSindicator2_p'].iloc[:, 24:180] = 0  \n",
    "# Set all values in the CSindicator2_m column from trial 25 to 180 to 0\n",
    "jags_input_s2_pre['CSindicator2_m'].iloc[:, 24:180] = 0  \n",
    "\n",
    "\n",
    "# jags_input_s2_pre WAS COMPARED IN THE CURRENT STAGE AND IT IS MATCHED\n",
    "# for key, df in jags_input_s2_pre.items():\n",
    "#     df.to_csv(f\"../../vars/r/draft/jags_py/jags_input_s2_pre_{key}_py.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5097be-9a65-4cbe-8fb5-31f438019801",
   "metadata": {},
   "source": [
    "### 2.3 Compute distance to CS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2389de-9f15-4479-8f44-90348378479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create CS index\n",
    "# Initialize empty matrices for the CSp_index and CSm_index\n",
    "jags_input_s2_pre['CSp_index'] = np.zeros_like(jags_input_s2_pre['CSindicator1_p'])\n",
    "jags_input_s2_pre['CSm_index'] = np.zeros_like(jags_input_s2_pre['CSindicator1_m'])\n",
    "# Loop through each row and column of the CSindicator1_p matrix\n",
    "for i in range(jags_input_s2_pre['CSindicator1_p'].shape[0]):\n",
    "    for j in range(jags_input_s2_pre['CSindicator1_p'].shape[1]):\n",
    "        # For each element in the matrix, set the value to the sum of the values in the first j columns of the same row\n",
    "        jags_input_s2_pre['CSp_index'][i, j] = np.sum(jags_input_s2_pre['CSindicator1_p'].iloc[i, :j+1])\n",
    "for i in range(jags_input_s2_pre['CSindicator1_m'].shape[0]):\n",
    "    for j in range(jags_input_s2_pre['CSindicator1_m'].shape[1]):\n",
    "        # For each element in the matrix, set the value to the sum of the values in the first j columns of the same row\n",
    "        jags_input_s2_pre['CSm_index'][i, j] = np.sum(jags_input_s2_pre['CSindicator1_m'].iloc[i, :j+1])\n",
    "jags_input_s2_pre['CSp_index'] = pd.DataFrame(jags_input_s2_pre['CSp_index'])\n",
    "jags_input_s2_pre['CSm_index'] = pd.DataFrame(jags_input_s2_pre['CSm_index'])\n",
    "\n",
    "\n",
    "# For all elements in the CSp_index matrix that are equal to 0, set their value to 1\n",
    "jags_input_s2_pre['CSp_index'] = jags_input_s2_pre['CSp_index'].replace(0, 1)\n",
    "# For all elements in the CSm_index matrix that are equal to 0, set their value to 1\n",
    "jags_input_s2_pre['CSm_index'] = jags_input_s2_pre['CSm_index'].replace(0, 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct comparing to R results\n",
    "# jags_input_s2_pre['CSm_index'].to_csv(\"../../vars/r/draft/csm_idx_py.csv\")\n",
    "# jags_input_s2_pre['CSp_index'].to_csv(\"../../vars/r/draft/csp_idx_py.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b415c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define the stimuli to process\n",
    "stimuli = [ \"CS+\",\"CS-\"]\n",
    "# stimuli = [ \"CS-\"]\n",
    "# Create a list to store results\n",
    "CS_per_s2_list = []\n",
    "# Create a list of data frames containing the Per_size column for the \"CS+\" and \"CS-\" stimuli\n",
    "for stimulus in stimuli:\n",
    "    # Filter the data for the current stimulus and select required columns\n",
    "    CS_per = data_s2[data_s2['stimulus'] == stimulus][['participant', 'Per_size']]\n",
    "    # Add a 'trials' column that numbers each row within each participant\n",
    "    CS_per['trials'] = CS_per.groupby('participant').cumcount() + 1\n",
    "    CS_per = CS_per[['participant', 'trials', 'Per_size']]\n",
    "    # Pivot the data to wide format\n",
    "    CS_per = CS_per.pivot(index='participant', columns='trials', values='Per_size')\n",
    "    CS_per.reset_index( inplace=True)\n",
    "    \n",
    "    # Initialize an empty matrix for storing the moving average values\n",
    "    CS_per_updatemean = pd.DataFrame(index=CS_per.index, columns=CS_per.columns)\n",
    "    \n",
    "    # Loop through each row and column of the CS_per DataFrame to compute the moving averages\n",
    "    for index, row in CS_per.iterrows():\n",
    "        for col in CS_per.columns:\n",
    "            # For each element in the matrix, set the value to the mean of the values in the first j columns of the corresponding row\n",
    "            values = row.loc[1:col].replace(np.nan, 0)  # Select values up to the current column\n",
    "            mean= values.mean(skipna=False)  # Compute mean, skipping NaNs\n",
    "            CS_per_updatemean.at[index, col] = round(mean,4)   \n",
    "    CS_per_updatemean = pd.DataFrame(CS_per_updatemean)\n",
    "    CS_per_updatemean.set_index(\"participant\", inplace=True)\n",
    "    # Store the DataFrame of moving average values in the list\n",
    "    CS_per_s2_list.append(CS_per_updatemean)\n",
    "\n",
    "# CS_per_s2_list is correct using R comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ced092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# d_list_s2\n",
    "# Initialize a list of four empty matrices for storing the distance values\n",
    "d_per_p = np.zeros((40, 180))\n",
    "d_per_m = np.zeros((40, 180))\n",
    "d_phy_p = np.zeros((40, 180))\n",
    "d_phy_m = np.zeros((40, 180))\n",
    "\n",
    "# This code loops through two nested for loops to calculate differences between\n",
    "# two variables (Sper, Sphy) and their corresponding counterparts (CS_per_s2_list, \n",
    "# CSphy_p, CSphy_m). The differences are calculated for each participant (1:40) \n",
    "# and each trial (1:180) and are stored in a data frame (d_list_s2).\n",
    "for i in range(40): #participants\n",
    "    for j in range(180): #trials\n",
    "        # Calculate difference between Sper and corresponding CS_per value for each trial and participant\n",
    "        # a=jags_input_s2_pre['Sper'].iloc[i, j]\n",
    "        # idx2 = int(jags_input_s2_pre['CSp_index'].iloc[i, j]) - 1\n",
    "        # b= CS_per_s2_list[0].iloc[i, idx2]\n",
    "        \n",
    "        d_per_p[i, j] = round(abs(jags_input_s2_pre['Sper'].iloc[i, j] - CS_per_s2_list[0].iloc[i, int(jags_input_s2_pre['CSp_index'].iloc[i, j] - 1)]), 2)\n",
    "        d_per_m[i, j] = round(abs(jags_input_s2_pre['Sper'].iloc[i, j] - CS_per_s2_list[1].iloc[i, int(jags_input_s2_pre['CSm_index'].iloc[i, j]) - 1]), 2)\n",
    "        \n",
    "        \n",
    "        # Calculate difference between Sphy and CSphy values for each trial and participant\n",
    "        d_phy_p[i, j] = round(abs(jags_input_s2_pre['Sphy'].iloc[i, j] - jags_input_s2_pre['CSphy_p'].iloc[i, j]), 2)\n",
    "        d_phy_m[i, j] = round(abs(jags_input_s2_pre['Sphy'].iloc[i, j] - jags_input_s2_pre['CSphy_m'].iloc[i, j]), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Convert matrices to DataFrames for merging\n",
    "d_per_p_df = pd.DataFrame(d_per_p, columns=[f'trial_{i+1}' for i in range(180)])\n",
    "d_per_m_df = pd.DataFrame(d_per_m, columns=[f'trial_{i+1}' for i in range(180)])\n",
    "d_phy_p_df = pd.DataFrame(d_phy_p, columns=[f'trial_{i+1}' for i in range(180)])\n",
    "d_phy_m_df = pd.DataFrame(d_phy_m, columns=[f'trial_{i+1}' for i in range(180)])\n",
    "\n",
    "\n",
    "d_per_p_df.index = d_per_p_df.index + 1\n",
    "d_per_m_df.index = d_per_m_df.index + 1\n",
    "d_phy_p_df.index = d_phy_p_df.index + 1\n",
    "d_phy_m_df.index = d_phy_m_df.index + 1\n",
    "\n",
    "\n",
    "def geValue_per_p(row):\n",
    "    participant = row['participant']\n",
    "    trial = row[\"trials\"]\n",
    "    column_name = f'trial_{trial}'\n",
    "    return d_per_p_df.at[participant, column_name]\n",
    "\n",
    "def geValue_per_m(row):\n",
    "    participant = row['participant']\n",
    "    trial = row[\"trials\"]\n",
    "    column_name = f'trial_{trial}'\n",
    "    return d_per_m_df.at[participant, column_name]\n",
    "\n",
    "\n",
    "def geValue_phy_p(row):\n",
    "    participant = row['participant']\n",
    "    trial = row[\"trials\"]\n",
    "    column_name = f'trial_{trial}'\n",
    "    return d_phy_p_df.at[participant, column_name]\n",
    "\n",
    "\n",
    "def geValue_phy_m(row):\n",
    "    participant = row['participant']\n",
    "    trial = row[\"trials\"]\n",
    "    column_name = f'trial_{trial}'\n",
    "    return d_phy_m_df.at[participant, column_name]\n",
    "\n",
    "data_s2[\"d_per_p\"] = data_s2.apply(geValue_per_p, axis=1)\n",
    "data_s2[\"d_per_m\"] = data_s2.apply(geValue_per_m, axis=1)\n",
    "data_s2[\"d_phy_p\"] = data_s2.apply(geValue_phy_p, axis=1)\n",
    "data_s2[\"d_phy_m\"] = data_s2.apply(geValue_phy_m, axis=1)\n",
    "\n",
    "# data_s2 = data_s2[[\"participant\", \"trials\", \"d_phy_m\", \"d_phy_p\", \"d_per_m\", \"d_per_p\", \"version\", \"timestamp\", \"block number\", \"trial number\", \"lost msec\", \"free VRAM\", \"trial contents\", \"US\", \"Startle_Circle\", \"Startle_ITI\", \"C1\", \"C2\", \"C3\", \"C5\", \"C4\", \"C6\", \"C7\", \"C8\", \"C9\", \"C10\", \"No_Startle\", \"Generalization_Block\", \"No_US\", \"Per_size\", \"US_expect\", \"Resp_Rev\", \"US_Intensity\", \"Total_trial_nr\", \"group\", \"stimulus\", \"stimulus_phy\", \"CSptrials\", \"CSmtrials\", \"USp\", \"USm\", \"CS_phy_p\", \"CS_phy_m\", \"Phy_size\"]]\n",
    "data_s2_cols = [\"participant\", \"trials\", \"d_phy_m\", \"d_phy_p\", \"d_per_m\", \"d_per_p\", \"block number\", \"trial number\",  \"US\", \"Startle_Circle\", \"Startle_ITI\", \"Per_size\",\"US_expect\",\"Total_trial_nr\", \"group\", \"stimulus\", \"stimulus_phy\",\"CSptrials\",\"CSmtrials\", \"USp\", \"USm\",\"CS_phy_p\",\"CS_phy_m\",\"Phy_size\"]\n",
    "data_s2 = data_s2[data_s2_cols]\n",
    "\n",
    "d_list_s2 = [d_per_p_df, d_per_m_df, d_phy_p_df, d_phy_m_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL CORRECT COMPARED  TO R \n",
    "# d_per_p_df.to_csv(f\"../../vars/r/draft/d_list_py/l_d_per_p_py.csv\")\n",
    "# d_per_m_df.to_csv(f\"../../vars/r/draft/d_list_py/l_d_per_m_py.csv\")\n",
    "# d_phy_p_df.to_csv(f\"../../vars/r/draft/d_list_py/l_d_phy_p_py.csv\")\n",
    "# d_phy_m_df.to_csv(f\"../../vars/r/draft/d_list_py/l_d_phy_m_py.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ed69f-d4c9-4413-9fd5-0c59bc009274",
   "metadata": {},
   "source": [
    "### 2.4 JAGS(PYMC) input file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e56fa-f63e-4de4-8b1f-8950eb4faf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_input_s2(L, indicator=None):\n",
    "    # Initialize data dictionary with fixed structure\n",
    "    data = {\n",
    "        'Nparticipants': jags_input_s2_pre['y'].shape[0],\n",
    "        'Ntrials': jags_input_s2_pre['y'].shape[1],\n",
    "        'Nactrials': 24,\n",
    "        'd_p_per': d_list_s2[0].iloc[:, 24:180] if L == 1 else d_list_s2[0],\n",
    "        'd_m_per': d_list_s2[1].iloc[:, 24:180] if L == 1 else d_list_s2[1],\n",
    "        'd_p_phy': d_list_s2[2].iloc[:, 24:180] if L == 1 else d_list_s2[2],\n",
    "        'd_m_phy': d_list_s2[3].iloc[:, 24:180] if L == 1 else d_list_s2[3],\n",
    "        'y': jags_input_s2_pre['y'].iloc[:, 24:180] if L == 1 else jags_input_s2_pre['y'],\n",
    "        # 'y2': np.array([jags_input_s2_pre['y'][:, 24:180], jags_input_s2_pre['y']][L - 1])\n",
    "    }\n",
    "\n",
    "    # Add conditional data based on the value of L and indicator\n",
    "    if L == 2:\n",
    "        additional_data = {\n",
    "            'r_plus': jags_input_s2_pre['US_p'],\n",
    "            'r_minus': jags_input_s2_pre['US_m'],\n",
    "            'k_plus': jags_input_s2_pre['CSindicator1_p' if indicator == 1 else 'CSindicator2_p'],\n",
    "            'k_minus': jags_input_s2_pre['CSindicator1_m' if indicator == 1 else 'CSindicator2_m']\n",
    "        }\n",
    "        data.update(additional_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Usage of the function with the specified arguments\n",
    "Data2_JAGSinput_G = data_input_s2(1)\n",
    "Data2_JAGSinput_LG = data_input_s2(2, 2)\n",
    "Data2_JAGSinput_CLG = data_input_s2(2, 1)\n",
    "\n",
    "\n",
    "\n",
    "save_data_as_pickle(Data2_JAGSinput_G, \"../../Data/res_py/Data2_JAGSinput_G.pkl\")\n",
    "save_data_as_pickle(Data2_JAGSinput_LG, \"../../Data/res_py/Data2_JAGSinput_LG.pkl\")\n",
    "save_data_as_pickle(Data2_JAGSinput_CLG, \"../../Data/res_py/Data2_JAGSinput_CLG.pkl\")\n",
    "save_data_as_pickle(data_s2, \"../../Data/res_py/Data_s2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a8b129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data2_JAGSinput_G, Data2_JAGSinput_LG, Data2_JAGSinput_CLG, data_s2 are checked and compared with R and they are correct\n",
    "# data_s2.to_csv(\"../../vars/r/draft/ds2_py.csv\")\n",
    "\n",
    "# keys = ['d_p_per', 'd_m_per', 'd_p_phy', 'd_m_phy', 'y',]\n",
    "# additional_keys = [ 'r_plus', 'r_minus', 'k_plus', 'k_minus']\n",
    "\n",
    "# _dfs = {\n",
    "#     \"G\": {\"items\": Data2_JAGSinput_G, \"keys\": keys }, \n",
    "#     \"LG\": {\"items\": Data2_JAGSinput_LG, \"keys\": keys  + additional_keys}, \n",
    "#     \"CLG\": {\"items\": Data2_JAGSinput_CLG, \"keys\": keys  + additional_keys}, \n",
    "# }\n",
    "\n",
    "# for frm, _v in _dfs.items():\n",
    "#     for k in _v['keys']:\n",
    "#         pd.DataFrame(_v[\"items\"][k]).to_csv(f\"../../vars/r/draft/jags2/{k}_{frm}_py.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237735a-05f7-44a2-b3b1-f453070a4331",
   "metadata": {},
   "source": [
    "### Save data files as csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26764e80-0741-48c2-bf64-9b5347aa9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s1.to_csv(\"../../Data/res_py/data_s1_py.csv\")\n",
    "data_s2.to_csv('../../Data/res_py/data_s2_py.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e449e0",
   "metadata": {},
   "source": [
    "## 3. Visuilization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85910dc3-dd80-4509-b8c1-6a25506dced9",
   "metadata": {},
   "source": [
    "### Prepare for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644cffd-1d55-426f-827f-32ab516883bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_s1_dropped =data_s1.dropna(axis='index', how='all', subset=['US_expect'])\n",
    "data_s2_dropped =data_s2.dropna(axis='index', how='all', subset=['US_expect'])\n",
    "data_list = [data_s1_dropped, data_s2_dropped]\n",
    "Nactrials = [Nactrials_1, Nactrials_2]  # Assuming these values are defined\n",
    "plot_list = []\n",
    "colors = ['red', 'blue'] \n",
    "root_folder = \"../../\"\n",
    "plts_folder = root_folder + \"Plots/py/1_DataCleanPlots/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f7dd7-5944-4d95-8f6b-f9dc0b26d0c0",
   "metadata": {},
   "source": [
    "### Learning:\n",
    "#### Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dcdc3b-c95f-4720-a48b-7edd5f75e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(data_list):\n",
    "    # Filter data to include only the first Nactrials[i] trials\n",
    "    filtered_data = data[data['trials'] <= Nactrials[i]]\n",
    "    \n",
    "    # Group by 'trials' and 'stimulus', and calculate mean and standard deviation\n",
    "    summarized_data = filtered_data.groupby(['trials', 'stimulus'], observed=False).agg(\n",
    "\n",
    "        mean_ac=('US_expect', 'mean'),\n",
    "        sd_ac=('US_expect', 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Merge back with filtered_data to calculate individual participant metrics\n",
    "    summarized_data = pd.merge(filtered_data, summarized_data, on=['trials', 'stimulus'])\n",
    "    summarized_data['mean_ac_indi'] = summarized_data.groupby(['trials', 'stimulus', 'participant'],observed=False)['US_expect'].transform('mean')\n",
    "    summarized_data['sd_ac'] = summarized_data.groupby(['trials', 'stimulus', 'participant'],observed=False)['US_expect'].transform('std')\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    ax = sns.lineplot(data=summarized_data, x='trials', y='mean_ac', hue='stimulus', style='stimulus', markers=True, err_style=\"bars\", errorbar='sd',  palette=colors)\n",
    "    \n",
    "    # Adding individual participant lines\n",
    "    for key, grp in summarized_data.groupby(['participant', 'stimulus'], observed=False):\n",
    "        ax = grp.plot(ax=ax, x='trials', y='mean_ac_indi', label='_nolegend_', color='grey', alpha=0.2)\n",
    "    \n",
    "    # Setting plot title and labels\n",
    "    ax.set_title(f\"Acquisition: Exp.{i+1}\")\n",
    "    ax.set_xlabel(\"Trials\")\n",
    "    ax.set_ylabel(\"US expectancy (1 - 10)\")\n",
    "    \n",
    "    # Setting axis limits and ticks\n",
    "    ax.set_ylim(0, 10.5)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    plt.legend(title='Stimulus', labels=['CS+', 'CS-'], title_fontsize='13', fontsize='11', loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"{plts_folder}1_Acquisition_Exp_{i+1}.jpg\", format='jpg', dpi=300)\n",
    "    # Store the plot in the list\n",
    "    plot_list.append(ax.get_figure())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d447365-30c4-49c4-810f-2896ba7dbdac",
   "metadata": {},
   "source": [
    "Individual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365345a-5700-47c7-b71a-c3a29de1aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(data_list):\n",
    "    # Filter data to include only the first Nactrials[i] trials\n",
    "    filtered_data = data[data['trials'] <= Nactrials[i]]\n",
    "    \n",
    "    # Calculate mean of US_expect by participant, trial, and stimulus\n",
    "    summarized_data = filtered_data.groupby(['participant', 'trials', 'stimulus'],observed=False).agg(\n",
    "        mean_ac=('US_expect', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Plotting with Seaborn and Matplotlib\n",
    "    g = sns.FacetGrid(summarized_data, col='participant', col_wrap=8, hue='stimulus', height=2.5, aspect=1)\n",
    "    g.map_dataframe(sns.lineplot, x='trials', y='mean_ac')\n",
    "    g.map_dataframe(sns.scatterplot, x='trials', y='mean_ac', s=30)\n",
    "    \n",
    "    # Customizing plots\n",
    "    g.set_titles(\"Participant {col_name}\")\n",
    "    g.set_axis_labels(\"Trials\", \"US Expectancy\")\n",
    "    g.add_legend(title=\"Stimulus\")\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.set_title(ax.get_title(), fontsize='small')\n",
    "        ax.set_ylim(0, 10.5)\n",
    "        ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))  # Ensures integer values on x-axis\n",
    "    \n",
    "    # Saving each plot in the list\n",
    "    g.savefig(f\"{plts_folder}2_Experiment_{i+1}.jpg\", format='jpg', dpi=300)\n",
    "    \n",
    "    plot_list.append(g)\n",
    "    g.figure.suptitle(f\"Experiment {i+1}\", y=1.02)\n",
    "    g.figure.tight_layout()\n",
    "    g.figure.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373b1d9-6538-4b85-b75b-1b4b8bb6d7e2",
   "metadata": {},
   "source": [
    "### Generalization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8750d4-795c-4503-9f00-5e871dcf028f",
   "metadata": {},
   "source": [
    "Group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0af825-c23f-48ac-a88b-ab7ea330913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_generalization(data, trials_threshold, title, stimulus_order, imgTitle):\n",
    "    filtered_data = data[data['trials'] > trials_threshold]\n",
    "    filtered_data['stimulus'] = pd.Categorical(filtered_data['stimulus'], categories=stimulus_order, ordered=True)\n",
    "\n",
    "    # Calculate mean and standard deviation of US_expect by stimulus and participant\n",
    "    summarized_data_indi = filtered_data.groupby(['stimulus', 'participant'], as_index=False, observed=False).agg(\n",
    "        mean_ge_indi=pd.NamedAgg(column='US_expect', aggfunc='mean'),\n",
    "        sd_ge_indi=pd.NamedAgg(column='US_expect', aggfunc='std')\n",
    "    )\n",
    "    \n",
    "    # Calculate mean and standard deviation of US_expect by stimulus\n",
    "    summarized_data = filtered_data.groupby('stimulus', as_index=False, observed=False).agg(\n",
    "        mean_ge=pd.NamedAgg(column='US_expect', aggfunc='mean'),\n",
    "        sd_ge=pd.NamedAgg(column='US_expect', aggfunc='std')\n",
    "    )\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot individual participant lines\n",
    "    sns.lineplot(data=summarized_data_indi, x='stimulus', y='mean_ge_indi', hue='participant', \n",
    "                 alpha=0.2, linewidth=0.5, legend=False)\n",
    "    \n",
    "    # Plot summary points\n",
    "    sns.scatterplot(data=summarized_data, x='stimulus', y='mean_ge', s=100, color='black')\n",
    "    \n",
    "    # Plot summary line\n",
    "    sns.lineplot(data=summarized_data, x='stimulus', y='mean_ge', linewidth=2, color='black')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Stimulus\")\n",
    "    plt.ylabel(\"US expectancy (1 - 10)\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Set limits and breaks for the y-axis\n",
    "    plt.ylim(0, 10.5)\n",
    "    plt.yticks([1, 5, 10])\n",
    "    \n",
    "    # Use the default theme with grid\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    plt.savefig(f\"{plts_folder}3_{imgTitle}\", format='jpg', dpi=300)\n",
    "\n",
    "    # Save figure in list\n",
    "    plot_list.append(plt.gcf())  # Store the current figure object\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328af262-73dd-48d8-88f8-c19a637b97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_generalization(data_list[0], Nactrials[0], \"Generalization: Exp.1\", ['S4','S5','S6', 'CS+','S8','S9','S10'], 'group_generalization_exp1.jpg')\n",
    "create_generalization(data_list[1], Nactrials[1], \"Generalization: Exp.2\", ['CS+','S2','S3','S4','S5','S6', 'S7','S8','S9','CS-'], 'group_generalization_exp2.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924b7f3-5ab8-4a12-bac2-423f5e113482",
   "metadata": {},
   "source": [
    "Individual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409082af-1353-47f0-a18b-350635620c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Individual(data, trials_threshold, title, imgTitle):\n",
    "    # Filter data to include only trials after the given threshold\n",
    "    filtered_data = data[data['trials'] > trials_threshold]\n",
    "\n",
    "    \n",
    "    # Calculate mean and standard deviation of US_expect by stimulus and participant\n",
    "    summarized_data = filtered_data.groupby(['stimulus', 'participant'], as_index=False).agg(\n",
    "        mean_ge=pd.NamedAgg(column='US_expect', aggfunc='mean'),\n",
    "        sd_ge=pd.NamedAgg(column='US_expect', aggfunc='std')\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create the plot\n",
    "    g = sns.FacetGrid(summarized_data, col=\"participant\", col_wrap=5, sharey=True, sharex=True)\n",
    "    g.map_dataframe(sns.pointplot, x='stimulus', y='mean_ge' )\n",
    "    g.map_dataframe(sns.lineplot, x='stimulus', y='mean_ge')\n",
    "    g.map(plt.errorbar, 'stimulus', 'mean_ge', 'sd_ge', fmt='o', capsize=5, capthick=1, ecolor='black')\n",
    "    \n",
    "    # Add labels and title\n",
    "    g.set_axis_labels(\"Stimulus\", \"US expectancy (1 - 10)\")\n",
    "    g.figure.suptitle(title, fontsize=16)\n",
    "    g.set(ylim=(0, 11))\n",
    "    plt.savefig(f\"{plts_folder}4_{imgTitle}\", format='jpg', dpi=300)\n",
    "\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plot_list.append(plt.gcf())  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abffcb9-2be0-45fb-bf68-dcc7b1c314a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_Individual(data_list[0], Nactrials_1, \"Experiment 1\", \"individual_generalization_exp1.jpg\")\n",
    "create_Individual(data_list[1], Nactrials_2, \"Experiment 2\", \"individual_generalization_exp1.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e9849-c71d-48ad-90ba-277b4357b6f5",
   "metadata": {},
   "source": [
    "### Perception:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32b15c-473e-4958-a8ca-6f2164009a1d",
   "metadata": {},
   "source": [
    "Group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef166cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b04138-c498-40ce-9cf0-4e9ee4019e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_perception_group_plot(data, title, img_title):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = sns.violinplot(\n",
    "        x=\"stimulus_phy\", \n",
    "        y=\"Per_size\", \n",
    "        data=data, \n",
    "        inner=None, \n",
    "        color=\"gray\", \n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    # Add points for individual data\n",
    "    sns.stripplot(\n",
    "        x=\"stimulus_phy\", \n",
    "        y=\"Per_size\", \n",
    "        data=data, \n",
    "        jitter=True, \n",
    "        size=2, \n",
    "        alpha=0.2, \n",
    "        color=\"black\", \n",
    "        dodge=True\n",
    "    )\n",
    "    \n",
    "    # Add the title and labels\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Stimulus\", fontsize=12)\n",
    "    plt.ylabel(\"Perceived Size\", fontsize=12)\n",
    "    \n",
    "    # Customize y-axis\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.ylim(0, 200)\n",
    "    plt.yticks(range(0, 201, 40))\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f\"{plts_folder}6_{img_title}\", format='jpg', dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64dda81-45ce-4d89-8b77-6b5402b7d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_perception_group_plot(data_list[0], \"Group Perception: Exp.1\", \"group_perception_exp1.jpg\")\n",
    "create_perception_group_plot(data_list[1], \"Group Perception: Exp.2\", \"group_perception_exp2.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c8321",
   "metadata": {},
   "source": [
    "Individuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_in_plot = []\n",
    "titles = [\"Experiment 1\", \"Experiment 2\"]\n",
    "for data in data_list:\n",
    "    data['stimulus_phy'] = data['stimulus_phy'].astype('category')\n",
    "\n",
    "# Set up the theme (equivalent to ggplot theme)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "P_in_plot = []\n",
    "\n",
    "for x, data in enumerate(data_list):\n",
    "    fig, axes = plt.subplots(5, 8, figsize=(20, 12))  # Adjust size for better spacing\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, participant_id in enumerate(sorted(data['participant'].unique())):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Filter data for each participant\n",
    "        participant_data = data[data['participant'] == participant_id]\n",
    "        \n",
    "        # Boxplot\n",
    "        sns.boxplot(\n",
    "            data=participant_data,\n",
    "            x='stimulus_phy',\n",
    "            y='Per_size',\n",
    "            ax=ax,\n",
    "            color=\"white\",\n",
    "            fliersize=0,  # Hide outliers\n",
    "            linewidth=0.8\n",
    "        )\n",
    "        \n",
    "        # Add red line for Phy_size\n",
    "        ax.plot(\n",
    "            participant_data['stimulus_phy'].cat.codes,\n",
    "            participant_data['Phy_size'],\n",
    "            color='red',\n",
    "            linewidth=1.2\n",
    "        )\n",
    "        \n",
    "        # Add red dots for Phy_size\n",
    "        ax.scatter(\n",
    "            participant_data['stimulus_phy'].cat.codes,\n",
    "            participant_data['Phy_size'],\n",
    "            color='red',\n",
    "            edgecolor='black',\n",
    "            s=30,\n",
    "            zorder=5\n",
    "        )\n",
    "        \n",
    "        # Adjust axis labels\n",
    "        ax.set_title(str(participant_id), fontsize=8)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_ylim(0, 200)\n",
    "        ax.set_yticks([0, 50, 100, 150, 200])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=6)\n",
    "\n",
    "    # Remove extra axes\n",
    "    for ax in axes[len(data['participant'].unique()):]:\n",
    "        ax.remove()\n",
    "\n",
    "    # Overall title for the experiment\n",
    "    fig.suptitle(titles[x], fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    P_in_plot.append(fig)\n",
    "\n",
    "# Show the plots (or you can save them using fig.savefig(\"filename.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
